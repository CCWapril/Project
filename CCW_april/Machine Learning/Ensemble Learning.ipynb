{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f0a665b",
   "metadata": {},
   "source": [
    "# 集成学习 Eensemble Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fd3d8f",
   "metadata": {},
   "source": [
    "https://blog.csdn.net/weixin_38753213/article/details/119686632  \n",
    "集成算法（Emseble Learning） 是构建多个学习器，然后通过一定策略结合把它们来完成学习任务的，常常可以获得比单一学习显著优越的学习器。  \n",
    "它本身不是一个单独的机器学习算法，而是通过数据上构建并结合多个机器学习器来完成学习任务。弱评估器被定义为是表现至少比随机猜测更好的模型，即预测准确率不低于50%的任意模型。  \n",
    "根据个体学习器的生产方式，目前的集成学习方法大致可分为两大类，即个体学习器间存在强依赖关系、必须串行生产的序列化方法，代表是Boosting。以及个体间不存在强依赖关系、可同时生产的并行化方法，代表是Bagging，和随机森林。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d795857",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# Added version check for recent scikit-learn 0.18 checks\n",
    "from distutils.version import LooseVersion as Version\n",
    "from sklearn import __version__ as sklearn_version\n",
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.preprocessing import StandardScaler  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97579110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class labels: [0 1 2]\n"
     ]
    }
   ],
   "source": [
    "iris = datasets.load_iris() \n",
    "#http://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html\n",
    "X = iris.data[:, :]\n",
    "y = iris.target  #取species列，类别\n",
    "print('Class labels:', np.unique(y))\n",
    "#Output:Class labels: [0 1 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3f4b119",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.50)  \n",
    "scaler = StandardScaler()  \n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)  \n",
    "X_test = scaler.transform(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "743da147",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[7. , 3.2, 4.7, 1.4],\n",
       "        [6.4, 3.2, 4.5, 1.5],\n",
       "        [6.9, 3.1, 4.9, 1.5],\n",
       "        [5.5, 2.3, 4. , 1.3],\n",
       "        [6.5, 2.8, 4.6, 1.5],\n",
       "        [5.7, 2.8, 4.5, 1.3],\n",
       "        [6.3, 3.3, 4.7, 1.6],\n",
       "        [4.9, 2.4, 3.3, 1. ],\n",
       "        [6.6, 2.9, 4.6, 1.3],\n",
       "        [5.2, 2.7, 3.9, 1.4],\n",
       "        [5. , 2. , 3.5, 1. ],\n",
       "        [5.9, 3. , 4.2, 1.5],\n",
       "        [6. , 2.2, 4. , 1. ],\n",
       "        [6.1, 2.9, 4.7, 1.4],\n",
       "        [5.6, 2.9, 3.6, 1.3],\n",
       "        [6.7, 3.1, 4.4, 1.4],\n",
       "        [5.6, 3. , 4.5, 1.5],\n",
       "        [5.8, 2.7, 4.1, 1. ],\n",
       "        [6.2, 2.2, 4.5, 1.5],\n",
       "        [5.6, 2.5, 3.9, 1.1],\n",
       "        [5.9, 3.2, 4.8, 1.8],\n",
       "        [6.1, 2.8, 4. , 1.3],\n",
       "        [6.3, 2.5, 4.9, 1.5],\n",
       "        [6.1, 2.8, 4.7, 1.2],\n",
       "        [6.4, 2.9, 4.3, 1.3],\n",
       "        [6.6, 3. , 4.4, 1.4],\n",
       "        [6.8, 2.8, 4.8, 1.4],\n",
       "        [6.7, 3. , 5. , 1.7],\n",
       "        [6. , 2.9, 4.5, 1.5],\n",
       "        [5.7, 2.6, 3.5, 1. ],\n",
       "        [5.5, 2.4, 3.8, 1.1],\n",
       "        [5.5, 2.4, 3.7, 1. ],\n",
       "        [5.8, 2.7, 3.9, 1.2],\n",
       "        [6. , 2.7, 5.1, 1.6],\n",
       "        [5.4, 3. , 4.5, 1.5],\n",
       "        [6. , 3.4, 4.5, 1.6],\n",
       "        [6.7, 3.1, 4.7, 1.5],\n",
       "        [6.3, 2.3, 4.4, 1.3],\n",
       "        [5.6, 3. , 4.1, 1.3],\n",
       "        [5.5, 2.5, 4. , 1.3],\n",
       "        [5.5, 2.6, 4.4, 1.2],\n",
       "        [6.1, 3. , 4.6, 1.4],\n",
       "        [5.8, 2.6, 4. , 1.2],\n",
       "        [5. , 2.3, 3.3, 1. ],\n",
       "        [5.6, 2.7, 4.2, 1.3],\n",
       "        [5.7, 3. , 4.2, 1.2],\n",
       "        [5.7, 2.9, 4.2, 1.3],\n",
       "        [6.2, 2.9, 4.3, 1.3],\n",
       "        [5.1, 2.5, 3. , 1.1],\n",
       "        [5.7, 2.8, 4.1, 1.3],\n",
       "        [6.3, 3.3, 6. , 2.5],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [7.1, 3. , 5.9, 2.1],\n",
       "        [6.3, 2.9, 5.6, 1.8],\n",
       "        [6.5, 3. , 5.8, 2.2],\n",
       "        [7.6, 3. , 6.6, 2.1],\n",
       "        [4.9, 2.5, 4.5, 1.7],\n",
       "        [7.3, 2.9, 6.3, 1.8],\n",
       "        [6.7, 2.5, 5.8, 1.8],\n",
       "        [7.2, 3.6, 6.1, 2.5],\n",
       "        [6.5, 3.2, 5.1, 2. ],\n",
       "        [6.4, 2.7, 5.3, 1.9],\n",
       "        [6.8, 3. , 5.5, 2.1],\n",
       "        [5.7, 2.5, 5. , 2. ],\n",
       "        [5.8, 2.8, 5.1, 2.4],\n",
       "        [6.4, 3.2, 5.3, 2.3],\n",
       "        [6.5, 3. , 5.5, 1.8],\n",
       "        [7.7, 3.8, 6.7, 2.2],\n",
       "        [7.7, 2.6, 6.9, 2.3],\n",
       "        [6. , 2.2, 5. , 1.5],\n",
       "        [6.9, 3.2, 5.7, 2.3],\n",
       "        [5.6, 2.8, 4.9, 2. ],\n",
       "        [7.7, 2.8, 6.7, 2. ],\n",
       "        [6.3, 2.7, 4.9, 1.8],\n",
       "        [6.7, 3.3, 5.7, 2.1],\n",
       "        [7.2, 3.2, 6. , 1.8],\n",
       "        [6.2, 2.8, 4.8, 1.8],\n",
       "        [6.1, 3. , 4.9, 1.8],\n",
       "        [6.4, 2.8, 5.6, 2.1],\n",
       "        [7.2, 3. , 5.8, 1.6],\n",
       "        [7.4, 2.8, 6.1, 1.9],\n",
       "        [7.9, 3.8, 6.4, 2. ],\n",
       "        [6.4, 2.8, 5.6, 2.2],\n",
       "        [6.3, 2.8, 5.1, 1.5],\n",
       "        [6.1, 2.6, 5.6, 1.4],\n",
       "        [7.7, 3. , 6.1, 2.3],\n",
       "        [6.3, 3.4, 5.6, 2.4],\n",
       "        [6.4, 3.1, 5.5, 1.8],\n",
       "        [6. , 3. , 4.8, 1.8],\n",
       "        [6.9, 3.1, 5.4, 2.1],\n",
       "        [6.7, 3.1, 5.6, 2.4],\n",
       "        [6.9, 3.1, 5.1, 2.3],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [6.8, 3.2, 5.9, 2.3],\n",
       "        [6.7, 3.3, 5.7, 2.5],\n",
       "        [6.7, 3. , 5.2, 2.3],\n",
       "        [6.3, 2.5, 5. , 1.9],\n",
       "        [6.5, 3. , 5.2, 2. ],\n",
       "        [6.2, 3.4, 5.4, 2.3],\n",
       "        [5.9, 3. , 5.1, 1.8]]),\n",
       " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_plus = y[y!=0]\n",
    "X_plus = X[y!=0]\n",
    "X_plus,y_plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ea1247c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_plus[y_plus==2] = 0\n",
    "y_plus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf5cd8b",
   "metadata": {},
   "source": [
    "## Bagging Classifier\n",
    "Bagging分类器是一种集成元估计器，它适合原始数据集的每个随机子集上的基分类器，然后将它们各自的预测(通过投票或平均)聚合成最终的预测。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98844e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "dt = DecisionTreeClassifier(random_state=1)\n",
    "bc = BaggingClassifier(base_estimator=dt, \n",
    "        n_estimators=50, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2931da02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy of bc: 0.95\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "bc.fit(X_train, y_train)\n",
    "y_pred = bc.predict(X_test)\n",
    "# 模型准确性评价\n",
    "acc_test = accuracy_score(y_pred, y_test)\n",
    "print('Test set accuracy of bc: {:.2f}'.format(acc_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5a0605",
   "metadata": {},
   "source": [
    "## 随机森林\n",
    "随机森林采用决策树作为弱分类器，在bagging的样本随机采样基础上，⼜加上了特征的随机选择。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80e4bd12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  0.9333333333333333\n",
      "Accuracy Score Normalized:  70\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=30)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print('Accuracy Score: ', \n",
    "      accuracy_score(y_test, y_pred))\n",
    "print('Accuracy Score Normalized: ',\n",
    "      accuracy_score(y_test, y_pred, normalize=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbd7842",
   "metadata": {},
   "source": [
    "### Additive model 加性模型\n",
    "广义加性模型GAM是一种在线性或Logistic回归模型（或任何其他广义线性模型）的框架内，构造非单调的响应模型的方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "046d986e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98\n",
      "LogisticGAM                                                                                               \n",
      "=============================================== ==========================================================\n",
      "Distribution:                      BinomialDist Effective DoF:                                      8.4684\n",
      "Link Function:                        LogitLink Log Likelihood:                                    -3.5372\n",
      "Number of Samples:                          100 AIC:                                               24.0111\n",
      "                                                AICc:                                              26.2252\n",
      "                                                UBRE:                                               2.3079\n",
      "                                                Scale:                                                 1.0\n",
      "                                                Pseudo R-Squared:                                    0.949\n",
      "==========================================================================================================\n",
      "Feature Function                  Lambda               Rank         EDoF         P > x        Sig. Code   \n",
      "================================= ==================== ============ ============ ============ ============\n",
      "s(0)                              [0.6]                20           5.4          9.95e-01                 \n",
      "s(1)                              [0.6]                20           2.4          9.15e-01                 \n",
      "s(2)                              [0.6]                20           0.6          9.98e-01                 \n",
      "s(3)                              [0.6]                20           0.1          8.00e-01                 \n",
      "intercept                                              1            0.0          4.75e-01                 \n",
      "==========================================================================================================\n",
      "Significance codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
      "\n",
      "WARNING: Fitting splines and a linear function to a feature introduces a model identifiability problem\n",
      "         which can cause p-values to appear significant when they are not.\n",
      "\n",
      "WARNING: p-values calculated in this manner behave correctly for un-penalized models or models with\n",
      "         known smoothing parameters, but when smoothing parameters have been estimated, the p-values\n",
      "         are typically lower than they should be, meaning that the tests reject the null too readily.\n"
     ]
    }
   ],
   "source": [
    "from pygam import LogisticGAM\n",
    " \n",
    "# 使用默认参数训练模型\n",
    "gam = LogisticGAM().fit(X_plus, y_plus)\n",
    "print(gam.accuracy(X_plus, y_plus))\n",
    "gam.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc5b530",
   "metadata": {},
   "source": [
    "### AdaBoost\n",
    "Adaboost 迭代算法就3步:\n",
    "\n",
    "初始化训练数据的权重。\n",
    "如果有N个样本，则每一个训练样本最开始时都被赋予相同的权值：1/N。\n",
    "\n",
    "训练弱分类器。\n",
    "具体训练过程中，如果某个样本点已经被准确地分类，那么在构造下一个训练集中，它的权值就被降低；相反，如果某个样本点没有被准确地分类，那么它的权值就得到提高。然后，权值更新过的样本集被用于训练下一个分类器，整个训练过程如此迭代地进行下去。\n",
    "\n",
    "将各个训练得到的弱分类器组合成强分类器。\n",
    "各个弱分类器的训练过程结束后，加大分类误差率小的弱分类器的权重，使其在最终的分类函数中起着较大的决定作用，而降低分类误差率大的弱分类器的权重，使其在最终的分类函数中起着较小的决定作用。换言之，误差率低的弱分类器在最终分类器中占的权重较大，否则较小。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2d3b970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ada Boost Algorithms\n",
      "\n",
      "Confusion Matrix\n",
      "____________________\n",
      "     Predicted\n",
      "     pos neg\n",
      "pos: 116 19\n",
      "neg: 116 19\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    " \n",
    "model = AdaBoostClassifier(n_estimators=100)\n",
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.50, random_state=None)\n",
    "sss.get_n_splits(X_plus, y_plus)\n",
    "\n",
    "cm_sum = np.zeros((2,2))\n",
    "\n",
    "for train_index, test_index in sss.split(X_plus, y_plus):\n",
    "    X_train, X_test = X_plus[train_index], X_plus[test_index]\n",
    "    y_train, y_test = y_plus[train_index], y_plus[test_index]\n",
    "#     print(y_test)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "#     print(y_pred)\n",
    "#     print(len(y_pred),sum(y_pred))\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    cm_sum = cm_sum + cm\n",
    "    \n",
    "print('\\nAda Boost Algorithms')\n",
    "print('\\nConfusion Matrix')\n",
    "print('_'*20)\n",
    "print('     Predicted')\n",
    "print('     pos neg')\n",
    "print('pos: %i %i' % (cm_sum[1,1], cm_sum[0,1]))\n",
    "print('neg: %i %i' % (cm_sum[1,1], cm_sum[0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f1caa20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  0.88\n",
      "Accuracy Score Normalized:  44\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    " \n",
    "print('Accuracy Score: ', accuracy_score(y_test, y_pred))\n",
    "print('Accuracy Score Normalized: ',accuracy_score(y_test, y_pred, normalize=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1f9cbe",
   "metadata": {},
   "source": [
    "### GBDT\n",
    "梯度提升(Gradient boosting) 是构建预测模型的最强大技术之一，它是集成算法中提升法(Boosting)的代表算法。  \n",
    "提升树利用加法模型与前向分歩算法实现学习的优化过程。当损失函数是平方误差损失函数和指数损失函数时，每一步优化是很简单的。但对一般损失函数而言，往往每一步优化并不那么容易。针对这一问题，Freidman提出了梯度提升算法。  \n",
    "Gradient Boosting是Boosting中的一大类算法，它的思想借鉴于梯度下降法，其基本原理是根据当前模型损失函数的负梯度信息来训练新加入的弱分类器，然后将训练好的弱分类器以累加的形式结合到现有模型中。  \n",
    "采用决策树作为弱分类器的Gradient Boosting算法被称为GBDT，有时又被称为MART（Multiple Additive Regression Tree）。GBDT中使用的决策树通常为CART。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7196669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gradient Boosting Algorithms\n",
      "\n",
      "Confusion Matrix\n",
      "____________________\n",
      "     Predicted\n",
      "     pos neg\n",
      "pos: 113 11\n",
      "neg: 113 11\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "model = GradientBoostingClassifier(n_estimators=100)\n",
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.50, random_state=None)\n",
    "sss.get_n_splits(X_plus, y_plus)\n",
    "\n",
    "cm_sum = np.zeros((2,2))\n",
    "\n",
    "for train_index, test_index in sss.split(X_plus, y_plus):\n",
    "    X_train, X_test = X_plus[train_index], X_plus[test_index]\n",
    "    y_train, y_test = y_plus[train_index], y_plus[test_index]\n",
    "#     print(y_test)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "#     print(y_pred)\n",
    "#     print(len(y_pred),sum(y_pred))\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    cm_sum = cm_sum + cm\n",
    "\n",
    "print('\\nGradient Boosting Algorithms')\n",
    "print('\\nConfusion Matrix')\n",
    "print('_'*20)\n",
    "print('     Predicted')\n",
    "print('     pos neg')\n",
    "print('pos: %i %i' % (cm_sum[1,1], cm_sum[0,1]))\n",
    "print('neg: %i %i' % (cm_sum[1,1], cm_sum[0,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09264b67",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a9c745b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "# XGboost 算法\n",
    "xgb = XGBClassifier(max_depth=5, learning_rate=0.01, n_estimators=2000, colsample_bytree=0.1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_plus, y_plus, test_size=0.25)\n",
    "xgb.fit(X_train,y_train)\n",
    "y_pred = xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5465df81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rmse of prediction is: 0.282842712474619\n",
      "XGBoost Regression Score: 0.92\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import metrics\n",
    " \n",
    "print('The rmse of prediction is:', mean_squared_error(y_test, y_pred) ** 0.5)\n",
    "print('XGBoost Regression Score:', xgb.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99f9701",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5222df16",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'learning_rate': 0.1,\n",
    "    'lambda_l1': 0.1,\n",
    "    'lambda_l2': 0.2,\n",
    "    'max_depth': 4,\n",
    "    'objective': 'binary',  # 目标函数\n",
    "}\n",
    " \n",
    "# 转换为Dataset数据格式\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "validation_data = lgb.Dataset(X_test, label=y_test)\n",
    "# 模型训练\n",
    "gbm = lgb.train(params, train_data, valid_sets=[validation_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cda6021b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 40, number of negative: 40\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000492 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 66\n",
      "[LightGBM] [Info] Number of data points in the train set: 80, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.317309\tvalid_0's binary_logloss: 0.476428\n",
      "The rmse of prediction is: 0.4472135954999579\n",
      "LightGBM Score: 0.8\n"
     ]
    }
   ],
   "source": [
    "# 安装LightGBM依赖包\n",
    "# pip install lightgbm\n",
    "import lightgbm as lgb\n",
    "from lightgbm import log_evaluation, early_stopping\n",
    "from sklearn import metrics\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_plus, y_plus, test_size = 0.2, random_state = 0)\n",
    "model = lgb.LGBMClassifier(num_leaves=31,\n",
    "                        learning_rate=0.05,\n",
    "                        n_estimators=20)\n",
    "\n",
    "callbacks = [log_evaluation(period=100), early_stopping(stopping_rounds=30)]\n",
    "model.fit(X_train, y_train,\n",
    "        eval_set=[(X_test, y_test)],\n",
    "        eval_metric='l1',\n",
    "        callbacks=callbacks)\n",
    " \n",
    "y_pred = model.predict(X_test, num_iteration=model.best_iteration_)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print('The rmse of prediction is:', mean_squared_error(y_test, y_pred) ** 0.5)\n",
    "print('LightGBM Score:', model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc5f5fe",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da01a826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6447531\ttotal: 142ms\tremaining: 567ms\n",
      "1:\tlearn: 0.5979172\ttotal: 143ms\tremaining: 214ms\n",
      "2:\tlearn: 0.5607884\ttotal: 143ms\tremaining: 95.6ms\n",
      "3:\tlearn: 0.5254190\ttotal: 144ms\tremaining: 36ms\n",
      "4:\tlearn: 0.4928742\ttotal: 144ms\tremaining: 0us\n",
      "Model is fitted: True\n",
      "Model params:\n",
      "{'iterations': 5, 'learning_rate': 0.1}\n",
      "CatBoost Score: 0.85\n"
     ]
    }
   ],
   "source": [
    "import catboost as cb\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\\\n",
    "# 调参，用网格搜索调出最优参数\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# params = {'depth': [4, 7, 10],\n",
    "#          'learning_rate': [0.03, 0.1, 0.15],\n",
    "#          'l2_leaf_reg': [1, 4, 9],\n",
    "#          'iterations': [300, 500]}\n",
    "#cb = cb.CatBoostClassifier()\n",
    "#cb_model = GridSearchCV(cb, params, scoring=\"roc_auc\", cv=3)\n",
    "#cb_model.fit(train, y_train)\n",
    "# 查看最佳分数\n",
    "# print(cb_model.best_score_)  \n",
    "# 查看最佳参数\n",
    "# print(cb_model.best_params_) \n",
    " \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_plus, y_plus, test_size = 0.2, random_state = 0)\n",
    " \n",
    "cb = CatBoostClassifier(iterations=5, learning_rate=0.1)\n",
    "cb.fit(X_train, y_train)\n",
    "# Categorical features选项的代码\n",
    "# cat_features_index = [0, 1, 2]\n",
    "#clf.fit(train, y_train, cat_features=cat_features_index)\n",
    "y_pred = cb.predict(X_test)\n",
    "print('Model is fitted: ' + str(cb.is_fitted()))\n",
    "print('Model params:')\n",
    "print(cb.get_params())\n",
    "print('CatBoost Score:', cb.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47c43d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "687a4ab6",
   "metadata": {},
   "source": [
    "PU learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6c3989",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624ab70c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ef73fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32f1585",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
