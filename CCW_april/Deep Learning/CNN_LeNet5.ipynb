{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "8haiwmoCpbGC"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JWmRbUiwj7iQ"
   },
   "source": [
    "# Get Knowing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "mD4f3OH0r_Fz"
   },
   "outputs": [],
   "source": [
    "MNISTtrain = pd.read_csv(\"mnist_train_small.csv\", header=None)\n",
    "MNISTtest = pd.read_csv(\"mnist_test.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "IgwT02v4uetI"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 785)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MNISTtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "FjBL-9meubKj"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "math.sqrt(784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0GWIeAwgvEwK"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(785,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample1 = MNISTtrain.iloc[0]\n",
    "sample1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "NGsgYWPEvOiL"
   },
   "outputs": [],
   "source": [
    "label1 = sample1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "XcV0bye1wEzB"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pixels = sample1[1:]\n",
    "pixels = np.array(pixels, dtype='uint8')\n",
    "pixels = pixels.reshape((28, 28))\n",
    "\n",
    "# Plot\n",
    "plt.title(f\"Label is {label1}.\")\n",
    "plt.imshow(pixels, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bqowVMD7j-OZ"
   },
   "source": [
    "# Create An Iterable Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "rTftplzhwUed"
   },
   "outputs": [],
   "source": [
    "class MNISTDataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, transforms=None):\n",
    "        self.X = df.iloc[:,1:]\n",
    "        self.y = df.iloc[:,0]\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.X.iloc[idx, :]\n",
    "        # image: ndarray\n",
    "        image = (np.array(image).astype(np.float32).reshape(28, 28, 1))\n",
    "        sample = {'image': image, 'label':(self.y[idx])}\n",
    "\n",
    "        if self.transforms:\n",
    "            sample['image'] = self.transforms(sample['image'])\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "rO7VWFuz0fSQ"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToPILImage(),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.1307,), (0.3081,))])\n",
    "# Converts a torch.*Tensor of shape C x H x W\n",
    "# or a numpy ndarray of shape H x W x C to a PIL Image\n",
    "# while adjusting the value range depending on the mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "93DZ_yR9zSqO"
   },
   "outputs": [],
   "source": [
    "# 数据转化\n",
    "trainset = MNISTDataSet(MNISTtrain, transforms=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "UHihBb-I1Bhb"
   },
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "6WQan68K0Szv"
   },
   "outputs": [],
   "source": [
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "rni5P14S07_T"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([64, 1, 28, 28]) torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "for i_batch, sample_batched in enumerate(trainloader):\n",
    "    if i_batch == 0:\n",
    "      print(i_batch, sample_batched['image'].size(),\n",
    "            sample_batched['label'].size())\n",
    "      break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cxHp3USA39iw"
   },
   "source": [
    "# CNN\n",
    "\n",
    "`torch.nn` has the layers we need.\n",
    "\n",
    "`torch.nn.functional` has the activation functions.\n",
    "\n",
    "The APIs can be found using the link at the bottom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "2JxNByXM1Dxx"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__LeNet5__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "_xz-C9ki4bTT"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5) # initial in_channel must be specified\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "# torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1,\n",
    "#                 groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)\n",
    "# out(Ni, Coutj) = bias(Coutj) + sumk(weight(Coutj, k) * input(Ni, k))\n",
    "# torch.nn.MaxPool2d(kernel_size, stride=None, padding=0,\n",
    "#                    dilation=1, return_indices=False, ceil_mode=False)\n",
    "# https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "VLNvBMgi5QKr"
   },
   "outputs": [],
   "source": [
    "net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_c7589S44fbH"
   },
   "source": [
    "Loss and optimizer: MNIST is the 10-class classification dataset. \n",
    "\n",
    "We use `CrossEntropyLoss` and `SGD`. \n",
    "\n",
    "Note that the `SGD` in `torch` is just gradient descent. \n",
    "\n",
    "We have already provided the \"mini-batch\" part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "HhD5dqur4cK7"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "YoVNYLsQ5IAs"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "hdOKdHCN5M8h"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.nn.parameter.Parameter'> torch.Size([6, 1, 5, 5])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([6])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([16, 6, 5, 5])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([16])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([120, 256])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([120])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([84, 120])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([84])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([10, 84])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for param in net.parameters():\n",
    "    print(type(param), param.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tDjlcNGt5VQi"
   },
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "ii63xyVK5TXA"
   },
   "outputs": [],
   "source": [
    "def trainBySGD(epochSize):\n",
    "    for epoch in range(epochSize):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data['image'], data['label']\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 100 == 99:    # print every 2000 mini-batches\n",
    "                print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "                running_loss = 0.0\n",
    "\n",
    "    print('Finished Training')\n",
    "# torch.nn.CrossEntropyLoss(weight=None, size_average=None, ignore_index=-100, \n",
    "#                           reduce=None, reduction='mean', label_smoothing=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "u9UOYPXK5dt5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 0.073\n",
      "[1,   200] loss: 0.016\n",
      "[1,   300] loss: 0.012\n",
      "[2,   100] loss: 0.008\n",
      "[2,   200] loss: 0.008\n",
      "[2,   300] loss: 0.008\n",
      "[3,   100] loss: 0.006\n",
      "[3,   200] loss: 0.005\n",
      "[3,   300] loss: 0.006\n",
      "[4,   100] loss: 0.004\n",
      "[4,   200] loss: 0.004\n",
      "[4,   300] loss: 0.004\n",
      "[5,   100] loss: 0.003\n",
      "[5,   200] loss: 0.004\n",
      "[5,   300] loss: 0.004\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "trainBySGD(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H4XL7Eo6mgJE"
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "Bff1Sd5d5e6k"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset = MNISTDataSet(MNISTtest, transforms=transform)\n",
    "testloader = DataLoader(testset, batch_size=batch_size, shuffle=True)\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "4O0zeXfrkRpD"
   },
   "outputs": [],
   "source": [
    "predictions = torch.LongTensor()\n",
    "truevalues = torch.LongTensor()\n",
    "loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "H7alNUMIkTUX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4, 8, 7, 1]) tensor([4, 8, 7, 1])\n",
      "tensor([7, 9, 7, 9]) tensor([7, 9, 5, 9])\n",
      "tensor([7, 7, 4, 7]) tensor([7, 7, 4, 7])\n",
      "tensor([8, 5, 6, 0]) tensor([8, 5, 6, 0])\n",
      "tensor([9, 1, 6, 0]) tensor([9, 1, 6, 0])\n",
      "tensor([4, 2, 3, 6]) tensor([4, 2, 3, 6])\n",
      "tensor([4, 5, 4, 6]) tensor([4, 5, 4, 6])\n",
      "tensor([3, 2, 0, 5]) tensor([3, 2, 0, 5])\n",
      "tensor([3, 3, 0, 7]) tensor([3, 3, 0, 7])\n",
      "tensor([2, 9, 8, 9]) tensor([2, 9, 8, 9])\n",
      "tensor([7, 3, 6, 0]) tensor([7, 3, 6, 0])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.0053, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for idx, eval_batched in enumerate(testloader):\n",
    "    images = eval_batched['image']\n",
    "    label_true = eval_batched['label']\n",
    "    preds = net(images)\n",
    "    predictions = torch.cat((predictions, preds.argmax(dim=1)), dim=0)\n",
    "    truevalues = torch.cat((truevalues, label_true), dim=0)\n",
    "    loss = criterion(preds, label_true)\n",
    "    if idx <= 10:\n",
    "      print(preds.argmax(dim=1)[0:4], label_true[0:4])\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k_q8zgW9kUU0"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
